{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = tf.keras.applications.resnet_v2.ResNet50V2\n",
    "preprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n",
    "decode_predictions = tf.keras.applications.resnet_v2.decode_predictions\n",
    "model = model_builder(weights=\"imagenet\", classifier_activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_masks_randomly(m, input_size, p, resolution):\n",
    "    low_res_size = (input_size[0] // resolution, input_size[1] // resolution) \n",
    "    masks = np.random.binomial(1, p, size=(m, *low_res_size)).astype(np.float32)\n",
    "\n",
    "    upscaled_masks = np.array([cv2.resize(mask, (input_size[1], input_size[0]), interpolation=cv2.INTER_LINEAR) for mask in masks])\n",
    "\n",
    "    upscaled_masks = upscaled_masks[..., np.newaxis]\n",
    "    \n",
    "    return upscaled_masks\n",
    "\n",
    "def perturbed_image(masks, image):\n",
    "    repeated_image = np.repeat(image[np.newaxis, ...], masks.shape[0], axis=0)\n",
    "    m_images = masks * repeated_image \n",
    "    return m_images\n",
    "\n",
    "def local_explanation(masks, mImages, classImage, model):\n",
    "    size_image = mImages.shape[1:3] \n",
    "    saliency_map = np.zeros(size_image, dtype=np.float32)\n",
    "\n",
    "    # Stack images for batch processing\n",
    "    preds = model.predict(mImages)\n",
    "\n",
    "    # Get predicted indices and top labels\n",
    "    top_labels = decode_predictions(preds, top=3)\n",
    "    \n",
    "    # Extract scores for the target class using a vectorized approach\n",
    "    scores = np.array([next((label[2] for label in top_labels[i] if label[1] == classImage), 0) for i in range(len(top_labels))])\n",
    "\n",
    "    # Calculate saliency map using vectorized operations\n",
    "    saliency_map = np.sum(masks * scores[:, np.newaxis, np.newaxis, np.newaxis], axis=0)\n",
    "\n",
    "    return saliency_map /len(masks)\n",
    "\n",
    "def rise_saliency(image, model, target_class, m=1000, p=0.5, resolution=8):\n",
    "    masks = generate_masks_randomly(m, image.shape, p, resolution)\n",
    "    perturbed_images = perturbed_image(masks, image)\n",
    "    saliency_map = local_explanation(masks, perturbed_images, target_class, model)\n",
    "    \n",
    "    return saliency_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 20/219\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:58\u001b[0m 2s/step"
     ]
    }
   ],
   "source": [
    "img_path = \"./data/African_elephant/ILSVRC2012_val_00048781.JPEG\"\n",
    "image = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = tf.keras.applications.xception.preprocess_input(image)\n",
    "\n",
    "target_class = 'African_elephant'\n",
    "saliency_map = rise_saliency(image, model, target_class, m=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "originalImage = cv2.resize(image/ 2 + 0.5, (224, 224))\n",
    "\n",
    "saliency_map_normalized = (saliency_map - np.min(saliency_map)) / (np.max(saliency_map) - np.min(saliency_map))\n",
    "\n",
    "alpha = 0.5 \n",
    "saliency_map_color = cv2.applyColorMap((saliency_map_normalized * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "saliency_map_color = cv2.cvtColor(saliency_map_color, cv2.COLOR_BGR2RGB) / 255.0  \n",
    "\n",
    "combined_image = (1 - alpha) * originalImage + alpha * saliency_map_color\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Affichage de l'image originale\n",
    "ax1.imshow(originalImage)\n",
    "ax1.set_title(\"Original Image\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Affichage de la carte de saillance\n",
    "ax2.imshow(saliency_map_normalized, cmap='jet')\n",
    "ax2.set_title(\"Saliency Map\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "# Affichage de la combinaison de l'image originale et de la carte de saillance\n",
    "ax3.imshow(combined_image, cmap='jet')\n",
    "ax3.set_title(\"Combined Image\")\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons observer que l'augmentation du nombre de masques entraîne une réduction des zones rouges incohérentes dans la carte de saillance. Cela peut s'expliquer par la loi des grands nombres,les fluctuations aléatoires tendent à se lisser, ce qui permet d'obtenir une carte de saillance plus stable et fiable.\n",
    "\n",
    "De plus, il est intéressant de noter que les zones qui ressortent dans la carte de saillance correspondent principalement aux contours et aux détails significatifs de l'image. Cela m que le modèle RISE réussit à identifier des caractéristiques essentielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
