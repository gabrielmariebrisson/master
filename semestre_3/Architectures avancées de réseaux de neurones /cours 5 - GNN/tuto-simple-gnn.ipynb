{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf2a222-2932-4c7a-901c-a7f9d4a3c5bd",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb917e56-44b3-428f-b0e9-168333024690",
   "metadata": {},
   "source": [
    "Inspired from PyTorch Geometric [series of tutorials](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73448c3",
   "metadata": {
    "id": "e73448c3"
   },
   "outputs": [],
   "source": [
    "#Execute the following line codes if executing in Python environment where pytorch_geometric is not installed\n",
    "#pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "#pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "#pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3983584",
   "metadata": {
    "id": "c3983584"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.datasets as datasets\n",
    "import torch_geometric.data as data\n",
    "import torch_geometric.transforms as transforms\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991e79d",
   "metadata": {
    "id": "7991e79d"
   },
   "source": [
    "## Part 2: Simple GNN in PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea37b6",
   "metadata": {
    "id": "eeea37b6"
   },
   "source": [
    "### Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ee147",
   "metadata": {
    "id": "322ee147"
   },
   "source": [
    "List all the available datasets. <br>\n",
    "Check online [documentation](https://pytorch-geometric.readthedocs.io/en/2.5.3/cheatsheet/data_cheatsheet.html) for statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381b78a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import NormalizeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea39f999",
   "metadata": {
    "id": "ea39f999",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f, weights_only=False) != _repr(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  f = osp.join(self.processed_dir, 'pre_filter.pt')\n"
     ]
    }
   ],
   "source": [
    "name = 'Cora'\n",
    "dataset = datasets.Planetoid('./data', name, transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14ab3b",
   "metadata": {},
   "source": [
    "We make use of **[data transformations](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-transforms) via `transform=NormalizeFeatures()`**.\n",
    "Transforms can be used to modify your input data before inputting them into a neural network, *e.g.*, for normalization or data augmentation.\n",
    "Here, we [row-normalize](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.NormalizeFeatures) the bag-of-words input feature vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b56f3-cf61-4450-acef-9f9340381aa9",
   "metadata": {},
   "source": [
    "### Implement a two layers GNN (with one hidden layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90969e75-9618-46df-92a9-5086d89742d8",
   "metadata": {},
   "source": [
    "Use of [`GCN`](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html#torch_geometric.nn.conv.GCNConv) graph convolutional layer.\n",
    "This graph convolutional operator is from the “Semi-supervised Classification with Graph Convolutional Networks” [paper](https://openreview.net/forum?id=SJU4ayYgl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f36576b7-9104-4d26-bdf3-d44a95a26edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16) #as for any layer (e.g., Conv2d) {in,out}_channels should be precised\n",
    "        #remind: input channels can be accessed through num_node_features attribute.\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index) #the forward pass takes as arguments the node embeddings `x` and edge list `edge_index`\n",
    "        x = F.relu(x)\n",
    "        #the modules can be combined with any other modules/functions from PyTorch\n",
    "        x = F.dropout(x, training=self.training) #default p=0.5, training indicate the mode={train,eval}\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b16b96-1d59-417a-a7c0-bc88201266e3",
   "metadata": {},
   "source": [
    "Training loop: <br>\n",
    "*N.B: similar as for other NNs. Note that mini-batching is not used for this node classification task for the reasons explained in previous tutorial.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28f1d8a-cf38-4b7e-8b31-577763e4aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) #use the training split predifined through attribute train_mask\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab3817-e807-4369-96a6-53c0f5bb1e8c",
   "metadata": {},
   "source": [
    "Evaluation: <br>\n",
    "*N.B: same as for other NNs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e5418c-dab2-4c52-b866-04f771f1a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "model.eval()#on the test split pre-defined through attribute test_mask\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58cea74-31fb-49af-ac61-b73cae16f700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077b19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
